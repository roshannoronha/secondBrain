- This century’s automated decision making systems combine individual adjudications with rulemaking while adhering to the procedural safeguards of neither. Automated systems jeapodize due norms
- Automation also defeats participatory rulemaking. Code, not rules, determines the outcomes of adjudications.
- In the past, computer systems helped humans apply rules to individual cases.9 Now, automated systems have become the primary decision makers.10 These systems often take human decision making out of the process of terminating individuals’ Medicaid, food stamp, and other welfare benefits.
- automation radically reduces the human role in executing government policy and programs, state and federal governments can cut staff and close field offices.
- automation ensures consistent decisions: systems interpret rules in the same way in every case
- also risks dismantling critical procedural safeguards at the foundation of administrative law. Whereas the differences between rulemaking and individual adjudications and their procedural safeguards animated twentieth-century administrative law,20 today’s automated systems defy such classification. Computer programs seamlessly combine rulemaking and individual adjudications without the critical procedural protections owed either of them.
- Automation also impairs the rulemaking procedures that traditionally substituted for individualized consideration with procedural due process. Although programmers building automated systems may not intend to engage in rulemaking, they in fact do so. Programmers routinely change the substance of rules when translating them from human language into computer code.27 The resulting distorted rules effectively constitute new policy that can affect large numbers of people.
- The opacity of automated systems shields them from scrutiny.28 Citizens cannot see or debate these new rules.29 In turn, the transparency, accuracy, and political accountability of administrative rulemaking are lost.30 Code writers lack the properly delegated authority and policy expertise that might ameliorate such unintentional policymaking.
- Agencies may be increasingly inclined to adopt policies involving simple questions and answers that are easy to translate into code, even when strong substantive reasons favor a more nuanced approach.31 At the same time, agencies may forsake policies that require a human being to exercise discretion because these are more difficult to automate. 
	- preference for simplified policy over nuance and discretion narrows the field for the expertise model of administrative law.
- Colorado Benefits Management System (CBMS) has issued hundreds of thousands of incorrect Medicaid, food stamp, and welfare eligibility determinations and benefit calculations since its launch in September 2004.39 Many of these errors can be attributed to programmers’ incorrect translations of hundreds of rules into computer code.40 As a result, CBMS imposed rules that, in their translated form, distorted federal and state policy without providing required opportunities for public input.
- These systems offend basic norms of due process by failing to provide both notice of the basis of their decisions and the means to review them. the procedural guarantees of the last century have been overmatched by the technologies of this one. 
- automated administrative state took root after the convergence of a number of trends—budget shortfalls in the 1990s, the falling costs and increased performance of information systems, and the emergence of the Internet.53 Government officials saw computerized automation as an efficient way to reduce operating costs.54 Automated systems meant less paperwork and fewer staff
	- computer systems determine whether children receive medical assistance, businesses obtain licenses and permits, and travelers board airplanes.56 All states automate a significant portion of the administration of their public benefits programs.57 More than fifty federal agencies execute policy with datamatching and data-mining programs.58  

- Automated decision systems have been characterized as rules-based programs, data-matching programs, or data-mining programs. 
- Policy is often distorted when programmers translate it into code. Although all translations shade meaning,68 the translation of policy from human language into code is more likely to result in a significant alteration of meaning than would the translation of policy from English into another human language.69 This is, in part, because the artificial languages intelligible to computers have a more limited vocabulary than human languages.70 Computer languages may be unable to capture the nuances of a particular policy.71 
- governments find it cost-effective to use the same system designers for a wide variety of programs,74 making it even less likely that a designer will have the necessary policy expertise in each distinct program. 
- Changes in policy made during its translation into code may also stem from the bias of the programmer.75 Programmers can build matching algorithms that have biased assumptions or limitations embedded in them.76 They can unconsciously phrase a question in a biased manner.
- Policy could be distorted by a code writer’s preference for binary questions, which can be easily translated into code.79 Government policy, however, often requires the weighing of multiple variables. For example, the Food Stamp Act and accompanying federal regulations limit unemployed, childless adults to three months of food stamps, but provide six exceptions to this rule, which then cross reference other exceptions that, in turn, refer to still other exceptions.80 Programmers may be tempted to write code employing a simplified three-month rule, leaving out the complicated and arguably confusing exceptions.81 Thus, code writers could end up distorting complicated policy through oversimplification.